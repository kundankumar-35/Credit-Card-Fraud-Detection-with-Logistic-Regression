# ğŸ’³ Credit Card Fraud Detection with Logistic Regression

## ğŸ“Œ Project Overview

This repository provides a step-by-step workflow for detecting fraudulent credit card transactions using Logistic Regression. The challenge lies in the highly imbalanced dataâ€”fraudulent transactions make up a tiny fraction of total transactions. To tackle this, we apply data balancing techniques and thorough feature engineering.

---

## ğŸ› ï¸ Workflow

<details>
<summary>ğŸ”¹ 1. Data Preprocessing</summary>
âœ… Loaded a large dataset (284,807 transactions, 31 features).  
âœ… No missing values detected.  
âœ… Features scaled (StandardScaler) for optimal model performance.  
âœ… Handled severe class imbalance via **undersampling**.
</details>  

---

<details>
<summary>ğŸ”¹ 2. Exploratory Data Analysis (EDA) ğŸ“Š</summary>
ğŸ” Examined class distribution: Only ~0.17% transactions are fraudulent.  
ğŸ“ˆ Compared transaction amounts: Frauds average higher amounts ($122 vs $88).  
ğŸ”— Feature correlations checked.
âš ï¸ Noted dataset is extremely imbalanced.
</details>  

---

<details>
<summary>ğŸ”¹ 3. Feature Engineering âš™ï¸</summary>
ğŸ§  Selected relevant features based on correlation and business knowledge.  
ğŸ”¢ Normalized transaction amounts and other features.
</details>  

---

<details>
<summary>ğŸ”¹ 4. Model Training ğŸ¤–</summary>
ğŸ Built and trained a **Logistic Regression** model.  
âš–ï¸ Used balanced data for training (undersampling).  
ğŸ”€ Employed train-test split for robust evaluation.
</details>  

---

<details>
<summary>ğŸ”¹ 5. Model Evaluation ğŸ“</summary>
Evaluated using:
- âœ… **Accuracy**: ~99% (but see note below)
- âœ… **Precision**
- âœ… **Recall** (focus on fraud detection)
- âœ… **F1-Score**
- âœ… **ROC-AUC Curve**

ğŸ”¥ **Special focus on Recall**: Minimizing false negatives is critical in fraud detectionâ€”catching fraud is more important than overall accuracy.

ğŸ† **Results (Example):**
| Metric      | Baseline (Imbalanced) | After Balancing |
|-------------|----------------------|----------------|
| Accuracy    | 99.8%                | 97.5%          |
| Recall (Fraud) | 20%                | 85%            |
| Precision   | 70%                  | 80%            |
| F1-Score    | 30%                  | 82%            |

*Note: Accuracy is high due to class imbalance. The key metric is recall for fraud cases.*

</details>  

---

## ğŸ“‚ Tech Stack

- **Language**: Python ğŸ
- **Libraries**: Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn

---

## ğŸš€ Key Takeaways

- Logistic Regression is effective for fraud detection when data imbalance is addressed.
- **Undersampling** greatly improves recall for fraudulent transactions.
- In fraud detection, recall and precision for fraud cases are more important than raw accuracy.

---

## ğŸ“ˆ Future Work

ğŸ”§ Apply **SMOTE** for synthetic oversampling.  
ğŸ§  Experiment with advanced models: Random Forest, XGBoost, Neural Networks.  
ğŸŒ Deploy model for real-time fraud detection.

---

âœ¨ This project shows how simple algorithms, when paired with proper preprocessing and balancing, can play a vital role in financial fraud prevention.
